# -*- coding: utf-8 -*-
"""Final CS 419  Project Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1KnEcyioGpfUwu4zBNRUElXgYjPJr-Had
"""

from google.colab import drive
drive.mount('/content/drive')

#importing all libraries used here
import pandas as pd
import numpy as np
import torch
from torch import nn
import matplotlib.pyplot as plt

#stock of which future prices are predicted
stock='SRTRANSFIN'

#loading data and creating features
raw_data = pd.read_csv("/content/drive/MyDrive/419_project/FINAL_FROM_DF.csv")
x=pd.to_datetime(raw_data['TIMESTAMP'])
raw_data['DATE']=x.dt.day
raw_data['MONTH']=x.dt.month
raw_data['YEAR']=x.dt.year
del x

x_stock = raw_data[raw_data.SYMBOL==stock][['SERIES','TIMESTAMP','DATE','MONTH','YEAR']]
x_stock=x_stock.reset_index()
x_stock=x_stock.drop(labels=['index'],axis=1)

temp=x_stock
t = temp.groupby("SERIES").size().sort_values().index
dic=dict()
for k in range(len(t)):
  dic[t[k]]=k+1
del temp,t
dic['nan']=0
print("series: ",dic)
temp=list(x_stock['SERIES'])
temp2=[]
for p in range(len(temp)):
  try:
    temp2.append(dic[str(temp[p])])
  except:
    print(temp[p])
temp=pd.DataFrame(temp2,columns=['SER'])

x_stock['N_SERIES']=temp['SER']
print(x_stock.columns)
size=len(x_stock)

"""Linear Regression"""

#linear regression class
class linearRegression(torch.nn.Module):
  def __init__(self,input_size,output_size):
    super(linearRegression,self).__init__()
    self.linear=torch.nn.Linear(input_size,output_size)
  def forward(self,x):
    out=self.linear(x)
    return out

#initializing model and other parameters
inputDim=4
outputDim=1
learningRate=1e-2
epochs=100
model=linearRegression(inputDim,outputDim)
loss_function=torch.nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(),lr=learningRate)

#training model in batch of 20 samples per iteration for each epoch
x_train=torch.tensor(x_stock.drop(labels=['SERIES','TIMESTAMP'],axis=1).to_numpy()).to(torch.float)
y_train=torch.tensor(raw_data[raw_data.SYMBOL==stock][['CLOSE']].to_numpy()).to(torch.float)
for epoch in range(epochs):
  for k in range(0,size,20):
    x=x_train[k:k+20]
    y=y_train[k:k+20]
    optimizer.zero_grad()
    output=model(x)
    loss=loss_function(output,y)
    loss.backward()
    optimizer.step()
  print('epoch {}, loss {}'.format(epoch,loss.item()))

x_t_eq = x_stock[x_stock.SERIES=='EQ']
x_t_eq=torch.tensor(x_t_eq.drop(labels=['SERIES','TIMESTAMP'],axis=1).to_numpy()).to(torch.float)
x_t_nw = x_stock[x_stock.SERIES=='NW']
x_t_nw=torch.tensor(x_t_nw.drop(labels=['SERIES','TIMESTAMP'],axis=1).to_numpy()).to(torch.float)
t1 = model(x_t_eq)
y_eq=[]
for k in t1:
  y_eq.append(k.item())
y_eq=pd.DataFrame(y_eq,columns=['CLOSE'])
t1=model(x_t_nw)
y_nw=[]
for k in t1:
  y_nw.append(k.item())
y_nw=pd.DataFrame(y_nw,columns=['CLOSE'])

# torch.save(model.state_dict,"/content/drive/MyDrive/419_project/model")

#future 1 month prediction
xf_eq1=[]
xf_eq2=[]
xf_nw1=[]
xf_nw2=[]
for k in range(1,31):   #creating 1 month features (January-2018) 
  xf_eq1.append([k,1,2018,dic['EQ']])
  xf_nw1.append([k,1,2018,dic['NW']])
  if k<10:
    xf_eq2.append("2018-01-0"+str(k))
    xf_nw2.append("2018-01-0"+str(k))
  else:
    xf_eq2.append("2018-01-"+str(k))
    xf_nw2.append("2018-01-"+str(k))

xf_eq1=torch.tensor(xf_eq1).to(torch.float)
xf_nw1=torch.tensor(xf_nw1).to(torch.float)
xf_eq2=pd.to_datetime(pd.DataFrame(xf_eq2,columns=['TIMESTAMP']).stack()).unstack()
xf_nw2=pd.to_datetime(pd.DataFrame(xf_nw2,columns=['TIMESTAMP']).stack()).unstack()
pred_eq=model(xf_eq1) #prediction
pred_nw=model(xf_nw1)
yf_eq=[]
yf_nw=[]
for y in pred_eq:
  yf_eq.append(y.item())
for y in pred_nw:
  yf_nw.append(y.item())
yf_eq=pd.DataFrame(yf_eq,columns=['CLOSE'])
yf_nw=pd.DataFrame(yf_nw,columns=['CLOSE'])

#plotting EQ series data
x_eq = x_stock[x_stock.SERIES=='EQ']['TIMESTAMP']
x_eq = pd.to_datetime(x_eq)
y_eq = y_eq
y_eq_a = raw_data[raw_data.SYMBOL==stock]
y_eq_a = y_eq_a[y_eq_a.SERIES=='EQ']['CLOSE']

f=plt.figure()
f.set_figwidth(30)
plt.scatter(x_eq,y_eq_a)
plt.scatter(x_eq,y_eq)
plt.scatter(xf_eq2,yf_eq)
plt.title("Training Data of SRTRANSFIN(EQ series)")
plt.legend(['Data','Prediction','Future Predictions'])
plt.show()

#plotting NW series data
x_nw = x_stock[x_stock.SERIES=='NW']['TIMESTAMP']
x_nw = pd.to_datetime(x_nw)
y_nw = y_nw
y_nw_a = raw_data[raw_data.SYMBOL==stock]
y_nw_a = y_nw_a[y_nw_a.SERIES=='NW']['CLOSE']

f=plt.figure()
f.set_figwidth(30)
plt.scatter(x_nw,y_nw_a)
plt.scatter(x_nw,y_nw)
plt.scatter(xf_nw2,yf_nw)
plt.title("Training Data of SRTRANSFIN(NW series)")
plt.legend(['Data','Prediction','Future Predictions'])
plt.show()

###LSTM###

data=pd.read_csv("/content/drive/MyDrive/419_project/FINAL_FROM_DF.csv")
stock='SRTRANSFIN'
data=data[data.SYMBOL==stock]
x=pd.DataFrame(pd.to_datetime(data['TIMESTAMP']),columns=['TIMESTAMP'])
data=data.drop(labels=["TIMESTAMP"],axis=1)
data=data.join(x).sort_values('TIMESTAMP').reset_index().drop(labels=['index'],axis=1)
s=len(data)
train=data[:int(0.7*s)]
test=data[int(0.7*s):]

x_train = train.iloc[:, 7:8].values
y_train = train.iloc[:, 5:6].values
x_test = test.iloc[:, 7:8].values
y_test = test.iloc[:, 5:6].values

scaler = StandardScaler()
scaler.fit(x_train)
x_train = scaler.transform(x_train)
scaler.fit(x_test)
x_test = scaler.transform(x_test)
scaler.fit(y_test)
y_test = scaler.transform(y_test)
scaler.fit(y_train)
y_train = scaler.transform(y_train)

x_t = []
y_t = []
for i in range(60, 3296):
  x_t.append(x_train[i-60:i,0])
  y_t.append(y_train[i,0])

x_t = np.array(x_t)
y_t = np.array(y_t)

x_t = np.reshape(x_t, (x_t.shape[0], x_t.shape[1],1))

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

rg = Sequential()
rg.add(LSTM(units = 50, return_sequences=True, input_shape = (x_t.shape[1],1)))
rg.add(Dropout(0.2))

rg.add(LSTM(units = 50, return_sequences= True))
rg.add(Dropout(0.2))

rg.add(LSTM(units = 50, return_sequences= True))
rg.add(Dropout(0.2))

rg.add(LSTM(units = 50))
rg.add(Dropout(0.2))

rg.add(Dense(units=1))

rg.compile(optimizer= 'adam', loss = 'mean_squared_error')
rg.fit(x_t, y_t, epochs = 100, batch_size = 32)

x_tt = []
for i in range(60,1413):
  x_tt.append(x_test[i-60:i, 0])
x_tt = np.array(x_tt)
x_tt  = np.reshape(x_tt, (x_tt.shape[0], x_tt.shape[1],1))

y_prediction5 = rg.predict(x_tt)

plt.plot(y_test, color = 'red', label = 'Actual stock price')
plt.plot(y_prediction5, color = 'blue', label = 'Predicted stock price')
plt.title('Comparison between actual and predicted stock prices')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()

y_test = y_test[60:]

np.sqrt(mean_squared_error(y_test, y_prediction5))

###Random Forest###

from sklearn.ensemble import RandomForestRegressor

df = pd.read_csv("/content/drive/MyDrive/419_project/FINAL_FROM_DF.csv")
x=pd.to_datetime(df['TIMESTAMP'])
df['DATE']=x.dt.day
df['MONTH']=x.dt.month
df['YEAR']=x.dt.year
del x

stock='SRTRANSFIN'

x_stock = df[df.SYMBOL==stock][['DATE','MONTH','YEAR']]
x_stock=torch.tensor(x_stock.to_numpy()).to(torch.float)
y_stock = df[df.SYMBOL==stock]['CLOSE']
y_stock=torch.tensor(y_stock.to_numpy()).to(torch.float)

model = RandomForestRegressor(n_jobs=-1)

estimators = np.arange(10, 200, 10)
scores = []
for n in estimators:
    model.set_params(n_estimators=n)
    model.fit(x_train, y_train)
    y_prediction4  = model.predict(x_test)
    scores.append(model.score(x_test, y_prediction4))
plt.title("Effect of n_estimators")
plt.xlabel("n_estimator")
plt.ylabel("score")
plt.plot(estimators, scores)

np.sqrt(mean_squared_error(y_test, y_prediction4))

plt.scatter(y_test, y_prediction4)
plt.xlabel("Actual Prices")
plt.ylabel(" Estimated Prices")
plt.title("Comparison between actual and estimated prices")
plt.show()

plt.plot(y_test, color = 'red', label = 'Actual stock price')
plt.plot(y_prediction4, color = 'blue', label = 'Predicted stock price')
plt.title('Comparison between actual and predicted stock prices')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()

###ANN####

import tensorflow.keras
from keras.models import Sequential
from keras.layers import Dense

df = pd.read_csv("/content/drive/MyDrive/419_project/FINAL_FROM_DF.csv")
x=pd.to_datetime(df['TIMESTAMP'])
df['DATE']=x.dt.day
df['MONTH']=x.dt.month
df['YEAR']=x.dt.year
del x

stock='SRTRANSFIN'

x_stock = df[df.SYMBOL==stock][['DATE','MONTH','YEAR']]
x_stock=torch.tensor(x_stock.to_numpy()).to(torch.float)
y_stock = df[df.SYMBOL==stock]['CLOSE']
y_stock=torch.tensor(y_stock.to_numpy()).to(torch.float)

model = Sequential()
model.add(Dense(256,activation='relu', input_dim = 3))
model.add(Dense(256,activation='relu'))
model.add(Dense(256,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(128,activation='relu'))
model.add(Dense(64,activation='relu'))
model.add(Dense(1, activation='linear'))
model.summary()

x_stock = df[df.SYMBOL==stock][['DATE','MONTH','YEAR']]
y_stock = df[df.SYMBOL==stock]['CLOSE']

x_train, x_test, y_train, y_test = train_test_split(x_stock, y_stock, test_size= 0.33 , random_state=42)

model.compile(optimizer= 'adam', loss='mean_squared_error')

epochs_hist=model.fit(x_train, y_train, epochs=100, batch_size= 100, verbose=1)

y_prediction3 = model.predict(x_test)

from sklearn.metrics import mean_squared_error

np.sqrt(mean_squared_error(y_test, y_prediction3))

plt.scatter(y_test, y_prediction3)
plt.xlabel("Actual Prices")
plt.ylabel(" Estimated Prices")
plt.title("Comparison between actual and estimated prices")
plt.show()

plt.plot(y_test, color = 'red', label = 'Actual stock price')
plt.plot(y_prediction3, color = 'blue', label = 'Predicted stock price')
plt.title('Comparison between actual and predicted stock prices')
plt.xlabel('Time')
plt.ylabel('Stock Price')
plt.legend()





